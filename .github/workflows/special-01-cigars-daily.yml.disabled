name: Cigars Daily Scraper

on:
  schedule:
    # Run daily at 5:30 AM UTC (12:30 AM EST) - Staggered timing to avoid conflicts
    - cron: '30 5 * * *'
  workflow_dispatch:  # Allow manual triggering

jobs:
  scrape-cigars-daily:
    runs-on: ubuntu-latest
    timeout-minutes: 45  # Allow up to 45 minutes for multiple categories
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        repository: SnickerSec/cigar-things
        token: ${{ secrets.PRIVATE_REPO_TOKEN }}
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install Chrome
      uses: browser-actions/setup-chrome@v1
      with:
        chrome-version: stable
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run Cigars Daily Scraper
      env:
        DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
        PYTHONPATH: ${{ github.workspace }}
        MAX_PAGES: 5  # Scrape up to 5 pages per category (Samplers + Economy Brands)
      run: |
        echo "ðŸŽ¯ Starting Cigars Daily scraping (Samplers + Economy Brands)..."
        echo "ðŸ“„ Maximum pages per category: $MAX_PAGES"
        python app/scrapers/deals/cigars_daily_scraper.py
        
    - name: Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: cigars-daily-scraper-logs
        path: |
          *.log
          /tmp/selenium-*.log
          /tmp/cigars_daily_debug.html
        retention-days: 7
        
    - name: Display completion summary
      if: success()
      run: |
        echo "âœ… Cigars Daily scraping completed successfully!"
        echo "ðŸ“¦ Scraped products from:"
        echo "   â€¢ Samplers category"
        echo "   â€¢ Economy Brands category"
        echo "ðŸ’¾ Data saved to production database"